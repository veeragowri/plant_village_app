# -*- coding: utf-8 -*-
"""plant village.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KguaDCwZF6JavVSv0jZ8tSDZx5pgXv1H
"""

from google.colab import drive
drive.mount('/content/drive')

import os

filtered_path = '/content/filtered_plant_disease'
os.makedirs(filtered_path, exist_ok=True)

import os

dataset_path = '/content/drive/MyDrive/PlantVillage'
print(os.listdir(dataset_path))

import os
import shutil

source_dir = '/content/drive/MyDrive/PlantVillage'
filtered_path = '/content/filtered_plant_disease'

selected_classes = [
    'Tomato_healthy',
    'Tomato_Bacterial_spot',
    'Tomato_Late_blight',
    'Potato___healthy',
    'Potato___Late_blight'
]

os.makedirs(filtered_path, exist_ok=True)

for class_name in selected_classes:
    src = os.path.join(source_dir, class_name)
    dst = os.path.join(filtered_path, class_name)

    if not os.path.exists(dst):  # ‚úÖ Only copy if not already exists
        if os.path.exists(src):
            shutil.copytree(src, dst)
            print(f"‚úÖ Copied: {class_name}")
        else:
            print(f"‚ùå Not found: {src}")
    else:
        print(f"‚è© Skipped (already exists): {class_name}")

!pip install tensorflow opencv-python matplotlib streamlit

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# Define image dimensions and batch size
IMG_HEIGHT = 128
IMG_WIDTH = 128
BATCH_SIZE = 32

# Load the dataset using image_dataset_from_directory
# This function automatically resizes, shuffles, and batches images.
# It also infers labels from subdirectory names.
train_ds = tf.keras.utils.image_dataset_from_directory(
    filtered_path,
    labels='inferred',
    label_mode='int', # Use 'int' for integer labels (sparse_categorical_crossentropy)
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    interpolation='nearest',
    batch_size=BATCH_SIZE,
    shuffle=True,
    validation_split=0.2, # 20% for validation
    subset='training',
    seed=123
)

val_ds = tf.keras.utils.image_dataset_from_directory(
    filtered_path,
    labels='inferred',
    label_mode='int',
    image_size=(IMG_HEIGHT, IMG_WIDTH),
    interpolation='nearest',
    batch_size=BATCH_SIZE,
    shuffle=True,
    validation_split=0.2,
    subset='validation',
    seed=123
)

# Get class names
class_names = train_ds.class_names
print(f"Class names: {class_names}")
num_classes = len(class_names)
print(f"Number of classes: {num_classes}")

# Normalize pixel values to [0, 1]
normalization_layer = tf.keras.layers.Rescaling(1./255)
train_ds_normalized = train_ds.map(lambda x, y: (normalization_layer(x), y))
val_ds_normalized = val_ds.map(lambda x, y: (normalization_layer(x), y))

# Prefetch for performance
AUTOTUNE = tf.data.AUTOTUNE
train_ds = train_ds_normalized.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds_normalized.cache().prefetch(buffer_size=AUTOTUNE)

# Verify a batch of data
for image_batch, label_batch in train_ds.take(1):
    print(image_batch.shape) # (batch_size, IMG_HEIGHT, IMG_WIDTH, 3)
    print(label_batch.shape) # (batch_size,)
    plt.figure(figsize=(10, 10))
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(image_batch[i].numpy())
        plt.title(class_names[label_batch[i]])
        plt.axis("off")
    plt.show()

from tensorflow.keras import layers, models

# Define the CNN architecture
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dropout(0.5), # Add dropout for regularization
    layers.Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False), # from_logits=False because we have softmax
              metrics=['accuracy'])

# Display model summary
model.summary()

# Train the model
EPOCHS = 15 # You can increase this for better accuracy, but be mindful of training time
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=EPOCHS
)

# Evaluate the model on the validation set
loss, accuracy = model.evaluate(val_ds)
print(f"Validation Loss: {loss:.4f}")
print(f"Validation Accuracy: {accuracy:.4f}")

# Plot training and validation accuracy/loss
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')
plt.show()

model.save("plant_disease_model.keras")

from google.colab import files
files.download("plant_disease_model.keras")  # or .keras

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# tensorflow
# opencv-python
# matplotlib
# numpy
# pandas
# streamlit
#

!pip install -r requirements.txt

# Install Streamlit
!pip install streamlit -q

# Install localtunnel to expose the Streamlit app publicly
!npm install localtunnel -g

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import tensorflow as tf
# from keras.models import load_model
# from PIL import Image
# import numpy as np
# import cv2
# import os
# 
# # Define the image size used during training
# IMG_SIZE = (128, 128)
# 
# # Load the trained model
# @st.cache_resource
# def load_my_model():
#     # Adjust path if you saved it differently, or load from /content/ if not using Drive
#     model_path = 'plant_disease_model.keras'
#     # In Colab, if saving to Drive, ensure it's mounted and path is correct.
#     # For simplicity in deployment, copy model to same dir as app.py if needed.
#     return load_model(model_path)
# 
# # Load model (make sure the .h5 file is in the same directory or accessible path)
# # If you saved it to Google Drive, you'll need to copy it to /content/ for Streamlit to find it
# # or adjust the path here. For this Colab setup, assume it's in the same /content/ directory
# # after being copied from Drive or downloaded.
# if not os.path.exists('plant_disease_model.keras'):
#     st.error("Model file 'plant_disease_model.keras' not found. Please ensure it's in the same directory as app.py or update the path.")
#     st.stop()
# 
# model = load_my_model()
# 
# # Class names (IMPORTANT: MUST be in the same order as trained)
# # Ensure these match the order from train_ds.class_names
# class_names = ['Potato_Late_blight', 'Potato_healthy', 'Tomato_Bacterial_spot', 'Tomato_Early_blight', 'Tomato_healthy']
# # Replace with your actual `class_names` from the training step.
# # You can print `train_ds.class_names` in the training section to confirm.
# 
# st.title("üåø Plant Disease Detector")
# st.write("Upload a leaf image to predict its disease status!")
# 
# uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "png", "jpeg"])
# 
# if uploaded_file is not None:
#     # Display the uploaded image
#     image = Image.open(uploaded_file)
#     st.image(image, caption='Uploaded Leaf Image', use_column_width=True)
#     st.write("")
#     st.write("Classifying...")
# 
#     # Pre-process the image
#     img_array = np.array(image)
#     # Convert RGB (Pillow) to BGR (OpenCV) if necessary for OpenCV processing
#     # Streamlit uses PIL, which is RGB. OpenCV uses BGR.
#     # If your model was trained with images loaded by OpenCV directly, they were BGR.
#     # If your model was trained with tf.keras.utils.image_dataset_from_directory,
#     # it typically loads as RGB. So, a direct conversion to RGB np array is fine.
#     # Ensure consistency with your training data loading.
#     # For `image_dataset_from_directory`, it loads as RGB, so no BGR conversion needed.
# 
#     # Resize the image
#     img_resized = cv2.resize(img_array, IMG_SIZE)
# 
#     # Normalize the image
#     img_normalized = img_resized / 255.0
# 
#     # Add batch dimension
#     img_input = np.expand_dims(img_normalized, axis=0)
# 
#     # Make prediction
#     predictions = model.predict(img_input)
#     predicted_class_index = np.argmax(predictions[0])
#     confidence = np.max(predictions[0]) * 100
# 
#     predicted_class_name = class_names[predicted_class_index]
# 
#     st.success(f"**Predicted Disease:** {predicted_class_name}")
#     st.write(f"**Confidence:** {confidence:.2f}%")
# 
#     st.markdown("---")
#     st.subheader("All Class Probabilities:")
#     for i, prob in enumerate(predictions[0]):
#         st.write(f"- {class_names[i]}: {prob*100:.2f}%")

!pip install pyngrok -q # Python wrapper for ngrok

from pyngrok import ngrok

# Replace 'YOUR_AUTHTOKEN' with the token you copied from ngrok.com
ngrok.set_auth_token("2yxqElYSCozfTr5KfQ1944QmKCL_5h9bakCo5Z5jZheDGCHn4")

import os
import threading
import time
import subprocess # Import subprocess

# Define the port Streamlit runs on
STREAMLIT_PORT = 8501

# Function to start Streamlit in a separate thread/process
def start_streamlit():
    # Use subprocess.Popen for better control and non-blocking execution
    process = subprocess.Popen(["streamlit", "run", "app.py", "--server.port", str(STREAMLIT_PORT), "--server.enableCORS", "false", "--server.enableXsrfProtection", "false"])
    # Wait a bit for Streamlit to start up
    time.sleep(5)
    return process

# Start Streamlit in the background
print(f"Starting Streamlit on port {STREAMLIT_PORT}...")
streamlit_process = start_streamlit() # Keep a reference to the process

# Start ngrok tunnel
print("Starting ngrok tunnel...")
try:
    public_url = ngrok.connect(STREAMLIT_PORT)
    print(f"Your Streamlit app is live at: {public_url}")
except Exception as e:
    print(f"Error starting ngrok tunnel: {e}")
    print("This might be due to a disconnected ngrok client or rate limits.")
    print("Please check your ngrok auth token and try again.")

# You might want to add a loop here to keep the Colab session alive
# and prevent the notebook from automatically shutting down if no other activity
# while True:
#     time.sleep(600) # Sleep for 10 minutes